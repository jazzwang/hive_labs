## 實作二

## Sqoop (2) : 將 MySQL 資料表匯出到 HDFS

### 執行記錄匯出

1. 請輸入如下指令並將「帳號」處替換成您的帳號：
<pre>
user@master ~ $ export DBID=帳號
user@master ~ $ sqoop import --connect "jdbc:mysql://master.3du.me/$DBID" --table mysql_data --username $DBID -P
Enter password: 輸入密碼
</pre>
1. 若資料轉換有正常執行，您將看到以下的類似訊息：
<pre>
13/12/22 11:34:54 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
13/12/22 11:34:54 INFO tool.CodeGenTool: Beginning code generation
13/12/22 11:34:55 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `mysql_data` AS t LIMIT 1
13/12/22 11:34:55 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `mysql_data` AS t LIMIT 1
13/12/22 11:34:55 INFO orm.CompilationManager: HADOOP_HOME is /opt/hadoopmr
Note: /tmp/sqoop-user/compile/b6d530fc526bb22521c01429e9559e63/mysql_data.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
13/12/22 11:34:58 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-user/compile/b6d530fc526bb22521c01429e9559e63/mysql_data.jar
13/12/22 11:34:58 WARN manager.MySQLManager: It looks like you are importing from mysql.
13/12/22 11:34:58 WARN manager.MySQLManager: This transfer can be faster! Use the --direct
13/12/22 11:34:58 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.
13/12/22 11:34:58 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)
13/12/22 11:34:58 INFO mapreduce.ImportJobBase: Beginning import of mysql_data
.
.. 略 ..
.
13/12/22 11:35:55 INFO mapreduce.ImportJobBase: Transferred 0 bytes in 55.3172 seconds (0 bytes/sec)
13/12/22 11:35:55 INFO mapreduce.ImportJobBase: Retrieved 2 records.
</pre>

### 檢查結果檔案

1. 轉換之結果，可於 HDFS 取得。請檢查目錄下是否有 mysql_data 資料夾。若轉換成功，您將看到 part-m-***** 的結果檔案。
<pre>
user@master ~ $ hadoop fs -ls mysql_data
-rw-------   3 user user          0 2013-12-22 11:35 mysql_data/_SUCCESS
drwxrwxr-x   - user user          0 2013-12-22 11:35 mysql_data/_logs
-rw-------   3 user user         16 2013-12-22 11:35 mysql_data/part-m-00000
</pre>
1. 檢視 part-m-***** 轉換結果
<pre>
user@master ~ $ hadoop fs -cat mysql_data/part-m-00000
1,Hello
2,World
</pre>

### 常見問題

* <備註 1> 若轉換失敗，您將會在目前的工作目錄看到一個與資料表同名的 java 檔案。在重新執行前，請先刪除該檔案。
<pre>
rm mysql_data.java
</pre>
* <備註 2> 若轉換成功，您將無法再跑第二次 sqoop import 指令。若想重新執行，請用 **hadoop fs -rmr mysql_data** 刪除現有結果。
<pre>
user@master ~ $ hadoop fs -rmr mysql_data
</pre>
* 或者在 sqoop import 指令中加上 **--target-dir \<dir\>** 來指定存放在 HDFS 的目標目錄。
<pre>
user@master ~ $ sqoop import --connect "jdbc:mysql://master.3du.me/$DBID" --table mysql_data --username $DBID -P --target-dir MYSQL_TMP
</pre>

### 參考資料

1. "[Sqoop: Big data conduit between NoSQL and RDBMS](http://www.ibm.com/developerworks/library/bd-sqoop/index.html)", [Surajit Paul](mailto:surajit.paul@in.ibm.com), Advisory Consultant, IBM, 23 Jul 2013

--------------------
本文件最後更新於：<script>document.write(document.lastModified);</script>
