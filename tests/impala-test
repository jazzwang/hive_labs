#!/bin/bash
DBID=$USER
PASSWORD='sqoop@lab'

echo "Test Case for Impala (1)"

hadoop fs -chmod g+w /user/hive/warehouse/${DBID}.db
impala-shell -q "SELECT 2+2; SELECT SUBSTR('Hello world',1,5); SELECT CAST(99.5 AS INT); SELECT CONCAT('aaa','bbb','ccc'); SELECT 2 > 1; SELECT NOW();"

echo "Test Case for Impala (2)"

impala-shell -q "SHOW DATABASES; SHOW TABLES; invalidate metadata; use $DBID; SHOW TABLES;"
impala-shell -q "use ${DBID};
CREATE TABLE Users ( id INT, name STRING );
CREATE TABLE Logins ( id INT, login TIMESTAMP );
INSERT INTO Users  VALUES ( 1, 'Jason' ), ( 2, 'Jazz' ), ( 3, 'Jim' ), ( 4, 'Steven' ), ( 5, 'Tim' );
INSERT INTO Logins VALUES ( 1, '2014-12-21 17:18:53' ), ( 2, '2014-12-20 21:38:42' ), ( 3, '2014-12-22 18:17:38' ), ( 4, '2014-12-23 09:25:35' ), ( 5, '2014-12-24 13:35:17' );
SELECT users.id, users.name, logins.login FROM users JOIN logins ON ( users.id = logins.id );"
hadoop fs -ls -R /user/hive/warehouse/$DBID.db
impala-shell -q "use $DBID; create table test (id int);"
hadoop fs -ls -R /user/hive/warehouse/$DBID.db
impala-shell -q "use $DBID;
COMPUTE STATS users;
COMPUTE STATS logins;
SHOW TABLE STATS users;
SHOW TABLE STATS logins;
SHOW COLUMN STATS users;
SHOW COLUMN STATS logins;"

echo "Test Case for Impala (3)"

cat > table1.csv << EOF
1,true,123.123,2012-10-24 08:55:00 
2,false,1243.5,2012-10-25 13:40:00
3,false,24453.325,2008-08-22 09:33:21.123
4,false,243423.325,2007-05-12 22:32:21.33454
5,true,243.325,1953-04-22 09:11:33
EOF

cat > table2.csv << EOF
1,true,12789.123
2,false,1243.5
3,false,24453.325
4,false,2423.3254
5,true,243.325
60,false,243565423.325
70,true,243.325
80,false,243423.325
90,true,243.325
EOF

hadoop fs -mkdir -p /tmp/$USER
hadoop fs -chmod a+w /tmp/$USER
hadoop fs -put table1.csv /tmp/$USER/table1.csv
hadoop fs -put table2.csv /tmp/$USER/table2.csv
hadoop fs -ls /tmp/$USER

impala-shell -q "CREATE TABLE $DBID.t1 ( id INT, col_1 BOOLEAN, col_2 DOUBLE, col_3 TIMESTAMP ) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' ;
CREATE TABLE $DBID.t2 ( id INT, col_1 BOOLEAN, col_2 DOUBLE ) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' ;
LOAD DATA INPATH '/tmp/$USER/table1.csv' INTO TABLE $DBID.t1 ;
LOAD DATA INPATH '/tmp/$USER/table2.csv' INTO TABLE $DBID.t2 ;"

impala-shell -q "use $DBID; SELECT * FROM t1; SELECT * FROM t2;"

impala-shell -q "use $DBID; SELECT t1.id, t1.col_1, MAX(t2.col_2), MIN(t2.col_2) FROM t2 JOIN t1 USING(id) GROUP BY id,col_1 ORDER BY id limit 10;"

impala-shell -q "use $DBID; EXPLAIN SELECT t1.id, t1.col_1, MAX(t2.col_2), MIN(t2.col_2) FROM t2 JOIN t1 USING(id) GROUP BY id,col_1 ORDER BY id limit 10;"

echo "Test Case for Impala (4)"

impala-shell -q "use $DBID;
CREATE TABLE logs ( field1 STRING , field2 STRING , field3 STRING ) PARTITIONED BY ( year STRING , month STRING , day STRING , host STRING ) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' ;
INSERT INTO logs PARTITION ( year = '2014' , month = '11' , day = '30' , host = 'host1' ) VALUES ( 'FTP', '192.168.70.10' , '/home/jazz/test1.log' ) ;
INSERT INTO logs PARTITION ( year = '2014' , month = '11' , day = '30' , host = 'host2' ) VALUES ( 'FTP', '192.168.70.11' , '/home/jazz/test2.log' ) ;
INSERT INTO logs PARTITION ( year = '2014' , month = '12' , day = '01' , host = 'host1' ) VALUES ( 'FTP', '192.168.70.10' , '/home/jazz/test3.log' ) ;
INSERT INTO logs PARTITION ( year = '2014' , month = '12' , day = '01' , host = 'host2' ) VALUES ( 'FTP', '192.168.70.11' , '/home/jazz/test4.log' ) ;
INSERT INTO logs PARTITION ( year = '2014' , month = '12' , day = '02' , host = 'host1' ) VALUES ( 'FTP', '192.168.70.10' , '/home/jazz/test5.log' ) ;
INSERT INTO logs PARTITION ( year = '2014' , month = '12' , day = '02' , host = 'host2' ) VALUES ( 'FTP', '192.168.70.11' , '/home/jazz/test6.log' ) ;"

hadoop fs -ls -R /user/hive/warehouse/$DBID.db/logs

impala-shell -q "SELECT * FROM $DBID.logs;"
